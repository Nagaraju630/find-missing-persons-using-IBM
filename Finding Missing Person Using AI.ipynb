{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing Keras Library\n",
    "import keras\n",
    "# Importing ImageDataGenerator class from keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters / arguments for ImageDataGenerator class\n",
    "train_datagen= ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  rotation_range=180,\n",
    "                                  horizontal_flip=True,\n",
    "                                  zoom_range=0.2)\n",
    "test_datagen= ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Applying ImageDataGenerator functionality to training_set\n",
    "x_train=train_datagen.flow_from_directory(r'directory_path\\trainset',\n",
    "                                          target_size=(64,64),batch_size=32,\n",
    "                                          class_mode='binary')\n",
    "# Note if more than 2 categories class_mode='categorical'\n",
    "# Note Change your Directory path before executing this Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Applying ImageDataGenerator functionality to testing_set\n",
    "x_test=train_datagen.flow_from_directory(r'directory_path\\testset',\n",
    "                                         target_size=(64,64),batch_size=32,\n",
    "                                         class_mode='binary')\n",
    "# Note if more than 2 categories class_mode='categorical'\n",
    "# Note Change your Directory path before executing this Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Found Missing': 0, 'Normal': 1}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Model Building Libraries\n",
    "# To define linear intialisation import sequential\n",
    "from tensorflow.keras.models import Sequential \n",
    "# To add Hidden layers import Dense\n",
    "from tensorflow.keras.layers import Dense \n",
    "# To Create Convolution Layer import convolution2D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "# Import Max pooling layer to extra maximum features\n",
    "from tensorflow.keras.layers import MaxPool2D \n",
    "# Importing Flatten Layer\n",
    "from tensorflow.keras.layers import Flatten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialising the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Convolutional Layer\n",
    "model.add(Conv2D( 32,3,3,input_shape=(64,64,3),activation='relu'))\n",
    "\n",
    "\n",
    "#1st param in conv2D = no of feature detectors(or say feature detector matrix) to form feature map\n",
    "#2nd,3rd param = size of feat.Detect(or say feature detector matrix size ie,. 3 X 3 here )\n",
    "#4th param = Expected image input shape(every img sould be of same size so here 64 X 64 and 3 means its an RGB img (2 means grayscale img and 1 for binary img(black and white))\n",
    "#5th param= Activation fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Max Pooling Layer\n",
    "model.add(MaxPool2D(pool_size=(2,2))) # 2,2 size of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Flatten Layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 21, 21, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Hidden Layer \n",
    "model.add(Dense(units=128,activation='relu',kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Output Layer \n",
    "model.add(Dense(units=1,activation='sigmoid',kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the Learning Process\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "8/8 [==============================] - 4s 548ms/step - loss: 0.6831 - accuracy: 0.6375 - val_loss: 0.6491 - val_accuracy: 0.6667\n",
      "Epoch 2/128\n",
      "8/8 [==============================] - 4s 441ms/step - loss: 0.6473 - accuracy: 0.6667 - val_loss: 0.6510 - val_accuracy: 0.6667\n",
      "Epoch 3/128\n",
      "8/8 [==============================] - 3s 435ms/step - loss: 0.6378 - accuracy: 0.6667 - val_loss: 0.6458 - val_accuracy: 0.6667\n",
      "Epoch 4/128\n",
      "8/8 [==============================] - 3s 427ms/step - loss: 0.6374 - accuracy: 0.6667 - val_loss: 0.6556 - val_accuracy: 0.6667\n",
      "Epoch 5/128\n",
      "8/8 [==============================] - 4s 439ms/step - loss: 0.6445 - accuracy: 0.6667 - val_loss: 0.6541 - val_accuracy: 0.6667\n",
      "Epoch 6/128\n",
      "8/8 [==============================] - 4s 453ms/step - loss: 0.6273 - accuracy: 0.6667 - val_loss: 0.6646 - val_accuracy: 0.6667\n",
      "Epoch 7/128\n",
      "8/8 [==============================] - 4s 476ms/step - loss: 0.6303 - accuracy: 0.6667 - val_loss: 0.6729 - val_accuracy: 0.6667\n",
      "Epoch 8/128\n",
      "8/8 [==============================] - 4s 486ms/step - loss: 0.6198 - accuracy: 0.6667 - val_loss: 0.6604 - val_accuracy: 0.6667\n",
      "Epoch 9/128\n",
      "8/8 [==============================] - 3s 427ms/step - loss: 0.6226 - accuracy: 0.6667 - val_loss: 0.6712 - val_accuracy: 0.6667\n",
      "Epoch 10/128\n",
      "8/8 [==============================] - 4s 464ms/step - loss: 0.6199 - accuracy: 0.6667 - val_loss: 0.6747 - val_accuracy: 0.6667\n",
      "Epoch 11/128\n",
      "8/8 [==============================] - 4s 441ms/step - loss: 0.6115 - accuracy: 0.6667 - val_loss: 0.6833 - val_accuracy: 0.6667\n",
      "Epoch 12/128\n",
      "8/8 [==============================] - 4s 457ms/step - loss: 0.6238 - accuracy: 0.6625 - val_loss: 0.6795 - val_accuracy: 0.6667\n",
      "Epoch 13/128\n",
      "8/8 [==============================] - 4s 473ms/step - loss: 0.6048 - accuracy: 0.6667 - val_loss: 0.7065 - val_accuracy: 0.6667\n",
      "Epoch 14/128\n",
      "8/8 [==============================] - 4s 461ms/step - loss: 0.6075 - accuracy: 0.6667 - val_loss: 0.6959 - val_accuracy: 0.6667\n",
      "Epoch 15/128\n",
      "8/8 [==============================] - 4s 456ms/step - loss: 0.6088 - accuracy: 0.6708 - val_loss: 0.7021 - val_accuracy: 0.6667\n",
      "Epoch 16/128\n",
      "8/8 [==============================] - 4s 450ms/step - loss: 0.6088 - accuracy: 0.6625 - val_loss: 0.6927 - val_accuracy: 0.6667\n",
      "Epoch 17/128\n",
      "8/8 [==============================] - 4s 451ms/step - loss: 0.5988 - accuracy: 0.6792 - val_loss: 0.7035 - val_accuracy: 0.6333\n",
      "Epoch 18/128\n",
      "8/8 [==============================] - 4s 447ms/step - loss: 0.6104 - accuracy: 0.6708 - val_loss: 0.6953 - val_accuracy: 0.6667\n",
      "Epoch 19/128\n",
      "8/8 [==============================] - 3s 429ms/step - loss: 0.6164 - accuracy: 0.6667 - val_loss: 0.6881 - val_accuracy: 0.6167\n",
      "Epoch 20/128\n",
      "8/8 [==============================] - 4s 450ms/step - loss: 0.6096 - accuracy: 0.6833 - val_loss: 0.7065 - val_accuracy: 0.6500\n",
      "Epoch 21/128\n",
      "8/8 [==============================] - 3s 433ms/step - loss: 0.5879 - accuracy: 0.6833 - val_loss: 0.7059 - val_accuracy: 0.6333\n",
      "Epoch 22/128\n",
      "8/8 [==============================] - 4s 465ms/step - loss: 0.5953 - accuracy: 0.6917 - val_loss: 0.6966 - val_accuracy: 0.6333\n",
      "Epoch 23/128\n",
      "8/8 [==============================] - 3s 424ms/step - loss: 0.6102 - accuracy: 0.7000 - val_loss: 0.6998 - val_accuracy: 0.6167\n",
      "Epoch 24/128\n",
      "8/8 [==============================] - 4s 447ms/step - loss: 0.5981 - accuracy: 0.6667 - val_loss: 0.7072 - val_accuracy: 0.6333\n",
      "Epoch 25/128\n",
      "8/8 [==============================] - 3s 433ms/step - loss: 0.6118 - accuracy: 0.6625 - val_loss: 0.6934 - val_accuracy: 0.6167\n",
      "Epoch 26/128\n",
      "8/8 [==============================] - 3s 435ms/step - loss: 0.5918 - accuracy: 0.6833 - val_loss: 0.7279 - val_accuracy: 0.6333\n",
      "Epoch 27/128\n",
      "8/8 [==============================] - 4s 454ms/step - loss: 0.6041 - accuracy: 0.6917 - val_loss: 0.7068 - val_accuracy: 0.6167\n",
      "Epoch 28/128\n",
      "8/8 [==============================] - 3s 415ms/step - loss: 0.5945 - accuracy: 0.6750 - val_loss: 0.7412 - val_accuracy: 0.6167\n",
      "Epoch 29/128\n",
      "8/8 [==============================] - 4s 448ms/step - loss: 0.5911 - accuracy: 0.7042 - val_loss: 0.7273 - val_accuracy: 0.5833\n",
      "Epoch 30/128\n",
      "8/8 [==============================] - 4s 451ms/step - loss: 0.6067 - accuracy: 0.6667 - val_loss: 0.7055 - val_accuracy: 0.6167\n",
      "Epoch 31/128\n",
      "8/8 [==============================] - 3s 395ms/step - loss: 0.6103 - accuracy: 0.6792 - val_loss: 0.6936 - val_accuracy: 0.5833\n",
      "Epoch 32/128\n",
      "8/8 [==============================] - 3s 433ms/step - loss: 0.6510 - accuracy: 0.6042 - val_loss: 0.6832 - val_accuracy: 0.6167\n",
      "Epoch 33/128\n",
      "8/8 [==============================] - 3s 412ms/step - loss: 0.6004 - accuracy: 0.6708 - val_loss: 0.7438 - val_accuracy: 0.6333\n",
      "Epoch 34/128\n",
      "8/8 [==============================] - 3s 422ms/step - loss: 0.5886 - accuracy: 0.6917 - val_loss: 0.6836 - val_accuracy: 0.6167\n",
      "Epoch 35/128\n",
      "8/8 [==============================] - 4s 488ms/step - loss: 0.5938 - accuracy: 0.6875 - val_loss: 0.7010 - val_accuracy: 0.6167\n",
      "Epoch 36/128\n",
      "8/8 [==============================] - 3s 409ms/step - loss: 0.5928 - accuracy: 0.6833 - val_loss: 0.7065 - val_accuracy: 0.6167\n",
      "Epoch 37/128\n",
      "8/8 [==============================] - 3s 404ms/step - loss: 0.5995 - accuracy: 0.6958 - val_loss: 0.7391 - val_accuracy: 0.6000\n",
      "Epoch 38/128\n",
      "8/8 [==============================] - 3s 420ms/step - loss: 0.5822 - accuracy: 0.6958 - val_loss: 0.6962 - val_accuracy: 0.5667\n",
      "Epoch 39/128\n",
      "8/8 [==============================] - 4s 442ms/step - loss: 0.5883 - accuracy: 0.6875 - val_loss: 0.7359 - val_accuracy: 0.6167\n",
      "Epoch 40/128\n",
      "8/8 [==============================] - 3s 420ms/step - loss: 0.6006 - accuracy: 0.6958 - val_loss: 0.7177 - val_accuracy: 0.5333\n",
      "Epoch 41/128\n",
      "8/8 [==============================] - 3s 420ms/step - loss: 0.5960 - accuracy: 0.7042 - val_loss: 0.7349 - val_accuracy: 0.6333\n",
      "Epoch 42/128\n",
      "8/8 [==============================] - 4s 499ms/step - loss: 0.5612 - accuracy: 0.7292 - val_loss: 0.6935 - val_accuracy: 0.6333\n",
      "Epoch 43/128\n",
      "8/8 [==============================] - 5s 600ms/step - loss: 0.5805 - accuracy: 0.7375 - val_loss: 0.7180 - val_accuracy: 0.6333\n",
      "Epoch 44/128\n",
      "8/8 [==============================] - 5s 623ms/step - loss: 0.5779 - accuracy: 0.6875 - val_loss: 0.6848 - val_accuracy: 0.6000\n",
      "Epoch 45/128\n",
      "8/8 [==============================] - 5s 615ms/step - loss: 0.5813 - accuracy: 0.7208 - val_loss: 0.7114 - val_accuracy: 0.6167\n",
      "Epoch 46/128\n",
      "8/8 [==============================] - 5s 617ms/step - loss: 0.5724 - accuracy: 0.7083 - val_loss: 0.6844 - val_accuracy: 0.6167\n",
      "Epoch 47/128\n",
      "8/8 [==============================] - 5s 589ms/step - loss: 0.5613 - accuracy: 0.7167 - val_loss: 0.6992 - val_accuracy: 0.5833\n",
      "Epoch 48/128\n",
      "8/8 [==============================] - 5s 607ms/step - loss: 0.5654 - accuracy: 0.6958 - val_loss: 0.7053 - val_accuracy: 0.6000\n",
      "Epoch 49/128\n",
      "8/8 [==============================] - 5s 595ms/step - loss: 0.5484 - accuracy: 0.7458 - val_loss: 0.7027 - val_accuracy: 0.6167\n",
      "Epoch 50/128\n",
      "8/8 [==============================] - 5s 570ms/step - loss: 0.5713 - accuracy: 0.7167 - val_loss: 0.7314 - val_accuracy: 0.5500\n",
      "Epoch 51/128\n",
      "8/8 [==============================] - 4s 487ms/step - loss: 0.5654 - accuracy: 0.7208 - val_loss: 0.7321 - val_accuracy: 0.5833\n",
      "Epoch 52/128\n",
      "8/8 [==============================] - 4s 499ms/step - loss: 0.5645 - accuracy: 0.7208 - val_loss: 0.7162 - val_accuracy: 0.6000\n",
      "Epoch 53/128\n",
      "8/8 [==============================] - 4s 509ms/step - loss: 0.5608 - accuracy: 0.7458 - val_loss: 0.7742 - val_accuracy: 0.6333\n",
      "Epoch 54/128\n",
      "8/8 [==============================] - 4s 536ms/step - loss: 0.5714 - accuracy: 0.7000 - val_loss: 0.7085 - val_accuracy: 0.5333\n",
      "Epoch 55/128\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.5746 - accuracy: 0.7250 - val_loss: 0.7032 - val_accuracy: 0.6167\n",
      "Epoch 56/128\n",
      "8/8 [==============================] - 5s 585ms/step - loss: 0.5522 - accuracy: 0.7042 - val_loss: 0.7160 - val_accuracy: 0.6167\n",
      "Epoch 57/128\n",
      "8/8 [==============================] - 7s 816ms/step - loss: 0.5513 - accuracy: 0.7042 - val_loss: 0.7518 - val_accuracy: 0.5833\n",
      "Epoch 58/128\n",
      "8/8 [==============================] - 7s 863ms/step - loss: 0.5555 - accuracy: 0.7292 - val_loss: 0.7058 - val_accuracy: 0.6500\n",
      "Epoch 59/128\n",
      "8/8 [==============================] - 7s 888ms/step - loss: 0.5394 - accuracy: 0.7208 - val_loss: 0.7437 - val_accuracy: 0.6500\n",
      "Epoch 60/128\n",
      "8/8 [==============================] - 6s 726ms/step - loss: 0.5541 - accuracy: 0.7375 - val_loss: 0.7135 - val_accuracy: 0.5833\n",
      "Epoch 61/128\n",
      "8/8 [==============================] - 5s 623ms/step - loss: 0.5680 - accuracy: 0.6917 - val_loss: 0.7053 - val_accuracy: 0.6000\n",
      "Epoch 62/128\n",
      "8/8 [==============================] - 5s 628ms/step - loss: 0.5353 - accuracy: 0.7458 - val_loss: 0.7184 - val_accuracy: 0.6000\n",
      "Epoch 63/128\n",
      "8/8 [==============================] - 5s 605ms/step - loss: 0.5753 - accuracy: 0.7125 - val_loss: 0.7382 - val_accuracy: 0.6000\n",
      "Epoch 64/128\n",
      "8/8 [==============================] - 5s 684ms/step - loss: 0.5761 - accuracy: 0.6917 - val_loss: 0.7008 - val_accuracy: 0.6500\n",
      "Epoch 65/128\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 0.5353 - accuracy: 0.7583 - val_loss: 0.6875 - val_accuracy: 0.6167\n",
      "Epoch 66/128\n",
      "8/8 [==============================] - 4s 551ms/step - loss: 0.5182 - accuracy: 0.7458 - val_loss: 0.7334 - val_accuracy: 0.6167\n",
      "Epoch 67/128\n",
      "8/8 [==============================] - 4s 558ms/step - loss: 0.5261 - accuracy: 0.7375 - val_loss: 0.7385 - val_accuracy: 0.6333\n",
      "Epoch 68/128\n",
      "8/8 [==============================] - 4s 477ms/step - loss: 0.5612 - accuracy: 0.7542 - val_loss: 0.6912 - val_accuracy: 0.6500\n",
      "Epoch 69/128\n",
      "8/8 [==============================] - 4s 520ms/step - loss: 0.5231 - accuracy: 0.7542 - val_loss: 0.7665 - val_accuracy: 0.6500\n",
      "Epoch 70/128\n",
      "8/8 [==============================] - 4s 521ms/step - loss: 0.5346 - accuracy: 0.7375 - val_loss: 0.6892 - val_accuracy: 0.5667\n",
      "Epoch 71/128\n",
      "8/8 [==============================] - 4s 474ms/step - loss: 0.5320 - accuracy: 0.7625 - val_loss: 0.8260 - val_accuracy: 0.6167\n",
      "Epoch 72/128\n",
      "8/8 [==============================] - 4s 498ms/step - loss: 0.5454 - accuracy: 0.7333 - val_loss: 0.6867 - val_accuracy: 0.6333\n",
      "Epoch 73/128\n",
      "8/8 [==============================] - 4s 485ms/step - loss: 0.5505 - accuracy: 0.7500 - val_loss: 0.7373 - val_accuracy: 0.6500\n",
      "Epoch 74/128\n",
      "8/8 [==============================] - 4s 536ms/step - loss: 0.5431 - accuracy: 0.7417 - val_loss: 0.7503 - val_accuracy: 0.5667\n",
      "Epoch 75/128\n",
      "8/8 [==============================] - 4s 492ms/step - loss: 0.5410 - accuracy: 0.7750 - val_loss: 0.7252 - val_accuracy: 0.6500\n",
      "Epoch 76/128\n",
      "8/8 [==============================] - 4s 486ms/step - loss: 0.5196 - accuracy: 0.7542 - val_loss: 0.7245 - val_accuracy: 0.6167\n",
      "Epoch 77/128\n",
      "8/8 [==============================] - 4s 502ms/step - loss: 0.5296 - accuracy: 0.7333 - val_loss: 0.7646 - val_accuracy: 0.5833\n",
      "Epoch 78/128\n",
      "8/8 [==============================] - 4s 491ms/step - loss: 0.5272 - accuracy: 0.7583 - val_loss: 0.7158 - val_accuracy: 0.6333\n",
      "Epoch 79/128\n",
      "8/8 [==============================] - 4s 518ms/step - loss: 0.5171 - accuracy: 0.7458 - val_loss: 0.7543 - val_accuracy: 0.6000\n",
      "Epoch 80/128\n",
      "8/8 [==============================] - 4s 475ms/step - loss: 0.5160 - accuracy: 0.7708 - val_loss: 0.7373 - val_accuracy: 0.6000\n",
      "Epoch 81/128\n",
      "8/8 [==============================] - 4s 494ms/step - loss: 0.5099 - accuracy: 0.7458 - val_loss: 0.7332 - val_accuracy: 0.6500\n",
      "Epoch 82/128\n",
      "8/8 [==============================] - 4s 509ms/step - loss: 0.5188 - accuracy: 0.7667 - val_loss: 0.7447 - val_accuracy: 0.6167\n",
      "Epoch 83/128\n",
      "8/8 [==============================] - 4s 479ms/step - loss: 0.5308 - accuracy: 0.7625 - val_loss: 0.6854 - val_accuracy: 0.7000\n",
      "Epoch 84/128\n",
      "8/8 [==============================] - 4s 516ms/step - loss: 0.5069 - accuracy: 0.7458 - val_loss: 0.7132 - val_accuracy: 0.6167\n",
      "Epoch 85/128\n",
      "8/8 [==============================] - 5s 644ms/step - loss: 0.5342 - accuracy: 0.7542 - val_loss: 0.7061 - val_accuracy: 0.6333\n",
      "Epoch 86/128\n",
      "8/8 [==============================] - 5s 597ms/step - loss: 0.5518 - accuracy: 0.7500 - val_loss: 0.7852 - val_accuracy: 0.6333\n",
      "Epoch 87/128\n",
      "8/8 [==============================] - 5s 648ms/step - loss: 0.5197 - accuracy: 0.7542 - val_loss: 0.6831 - val_accuracy: 0.6333\n",
      "Epoch 88/128\n",
      "8/8 [==============================] - 5s 593ms/step - loss: 0.4986 - accuracy: 0.7708 - val_loss: 0.6830 - val_accuracy: 0.6667\n",
      "Epoch 89/128\n",
      "8/8 [==============================] - 5s 590ms/step - loss: 0.4888 - accuracy: 0.7917 - val_loss: 0.7348 - val_accuracy: 0.6500\n",
      "Epoch 90/128\n",
      "8/8 [==============================] - 5s 636ms/step - loss: 0.4927 - accuracy: 0.7708 - val_loss: 0.6825 - val_accuracy: 0.6833\n",
      "Epoch 91/128\n",
      "8/8 [==============================] - 5s 592ms/step - loss: 0.5036 - accuracy: 0.7583 - val_loss: 0.6877 - val_accuracy: 0.6333\n",
      "Epoch 92/128\n",
      "8/8 [==============================] - 4s 533ms/step - loss: 0.4964 - accuracy: 0.8042 - val_loss: 0.6980 - val_accuracy: 0.6333\n",
      "Epoch 93/128\n",
      "8/8 [==============================] - 4s 502ms/step - loss: 0.4760 - accuracy: 0.7917 - val_loss: 0.6789 - val_accuracy: 0.6667\n",
      "Epoch 94/128\n",
      "8/8 [==============================] - 4s 523ms/step - loss: 0.4815 - accuracy: 0.7583 - val_loss: 0.6845 - val_accuracy: 0.6333\n",
      "Epoch 95/128\n",
      "8/8 [==============================] - 5s 570ms/step - loss: 0.4862 - accuracy: 0.8083 - val_loss: 0.7577 - val_accuracy: 0.6667\n",
      "Epoch 96/128\n",
      "8/8 [==============================] - 5s 595ms/step - loss: 0.5084 - accuracy: 0.7542 - val_loss: 0.6903 - val_accuracy: 0.5667\n",
      "Epoch 97/128\n",
      "8/8 [==============================] - 5s 590ms/step - loss: 0.4915 - accuracy: 0.7917 - val_loss: 0.7037 - val_accuracy: 0.6667\n",
      "Epoch 98/128\n",
      "8/8 [==============================] - 4s 544ms/step - loss: 0.4759 - accuracy: 0.7708 - val_loss: 0.7025 - val_accuracy: 0.6167\n",
      "Epoch 99/128\n",
      "8/8 [==============================] - 4s 517ms/step - loss: 0.5110 - accuracy: 0.7625 - val_loss: 0.7077 - val_accuracy: 0.5667\n",
      "Epoch 100/128\n",
      "8/8 [==============================] - 4s 500ms/step - loss: 0.5555 - accuracy: 0.7208 - val_loss: 0.8185 - val_accuracy: 0.6167\n",
      "Epoch 101/128\n",
      "8/8 [==============================] - 4s 489ms/step - loss: 0.4718 - accuracy: 0.7583 - val_loss: 0.6971 - val_accuracy: 0.6833\n",
      "Epoch 102/128\n",
      "8/8 [==============================] - 4s 533ms/step - loss: 0.4928 - accuracy: 0.7708 - val_loss: 0.7236 - val_accuracy: 0.6500\n",
      "Epoch 103/128\n",
      "8/8 [==============================] - 4s 525ms/step - loss: 0.4911 - accuracy: 0.7917 - val_loss: 0.7264 - val_accuracy: 0.7000\n",
      "Epoch 104/128\n",
      "8/8 [==============================] - 4s 540ms/step - loss: 0.4623 - accuracy: 0.7917 - val_loss: 0.6829 - val_accuracy: 0.6333\n",
      "Epoch 105/128\n",
      "8/8 [==============================] - 6s 742ms/step - loss: 0.5039 - accuracy: 0.7458 - val_loss: 0.7234 - val_accuracy: 0.5667\n",
      "Epoch 106/128\n",
      "8/8 [==============================] - 4s 561ms/step - loss: 0.5107 - accuracy: 0.7417 - val_loss: 0.8552 - val_accuracy: 0.6500\n",
      "Epoch 107/128\n",
      "8/8 [==============================] - 4s 555ms/step - loss: 0.4934 - accuracy: 0.7583 - val_loss: 0.6865 - val_accuracy: 0.6500\n",
      "Epoch 108/128\n",
      "8/8 [==============================] - 4s 523ms/step - loss: 0.4585 - accuracy: 0.8042 - val_loss: 0.6383 - val_accuracy: 0.6167\n",
      "Epoch 109/128\n",
      "8/8 [==============================] - 4s 544ms/step - loss: 0.4630 - accuracy: 0.8208 - val_loss: 0.7627 - val_accuracy: 0.6333\n",
      "Epoch 110/128\n",
      "8/8 [==============================] - 4s 501ms/step - loss: 0.4683 - accuracy: 0.7833 - val_loss: 0.6833 - val_accuracy: 0.6167\n",
      "Epoch 111/128\n",
      "8/8 [==============================] - 4s 489ms/step - loss: 0.4890 - accuracy: 0.7833 - val_loss: 0.7569 - val_accuracy: 0.6167\n",
      "Epoch 112/128\n",
      "8/8 [==============================] - 4s 493ms/step - loss: 0.5043 - accuracy: 0.7625 - val_loss: 0.7124 - val_accuracy: 0.6833\n",
      "Epoch 113/128\n",
      "8/8 [==============================] - 4s 517ms/step - loss: 0.5025 - accuracy: 0.7792 - val_loss: 0.6521 - val_accuracy: 0.6667\n",
      "Epoch 114/128\n",
      "8/8 [==============================] - 4s 482ms/step - loss: 0.4813 - accuracy: 0.8000 - val_loss: 0.7192 - val_accuracy: 0.6833\n",
      "Epoch 115/128\n",
      "8/8 [==============================] - 4s 491ms/step - loss: 0.4565 - accuracy: 0.8083 - val_loss: 0.6382 - val_accuracy: 0.6167\n",
      "Epoch 116/128\n",
      "8/8 [==============================] - 4s 493ms/step - loss: 0.4487 - accuracy: 0.7958 - val_loss: 0.7695 - val_accuracy: 0.6167\n",
      "Epoch 117/128\n",
      "8/8 [==============================] - 4s 503ms/step - loss: 0.4643 - accuracy: 0.8042 - val_loss: 0.7123 - val_accuracy: 0.6333\n",
      "Epoch 118/128\n",
      "8/8 [==============================] - 4s 490ms/step - loss: 0.4642 - accuracy: 0.8000 - val_loss: 0.7376 - val_accuracy: 0.6167\n",
      "Epoch 119/128\n",
      "8/8 [==============================] - 4s 498ms/step - loss: 0.4675 - accuracy: 0.8125 - val_loss: 0.7929 - val_accuracy: 0.6000\n",
      "Epoch 120/128\n",
      "8/8 [==============================] - 4s 524ms/step - loss: 0.4622 - accuracy: 0.8042 - val_loss: 0.6797 - val_accuracy: 0.6167\n",
      "Epoch 121/128\n",
      "8/8 [==============================] - 4s 494ms/step - loss: 0.4704 - accuracy: 0.8167 - val_loss: 0.7155 - val_accuracy: 0.6167\n",
      "Epoch 122/128\n",
      "8/8 [==============================] - 4s 515ms/step - loss: 0.4624 - accuracy: 0.7708 - val_loss: 0.7608 - val_accuracy: 0.5667\n",
      "Epoch 123/128\n",
      "8/8 [==============================] - 6s 736ms/step - loss: 0.4911 - accuracy: 0.7417 - val_loss: 0.7631 - val_accuracy: 0.6667\n",
      "Epoch 124/128\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 0.4858 - accuracy: 0.7708 - val_loss: 0.7610 - val_accuracy: 0.6833\n",
      "Epoch 125/128\n",
      "8/8 [==============================] - 5s 595ms/step - loss: 0.4903 - accuracy: 0.7667 - val_loss: 0.7283 - val_accuracy: 0.6667\n",
      "Epoch 126/128\n",
      "8/8 [==============================] - 5s 599ms/step - loss: 0.4767 - accuracy: 0.7667 - val_loss: 0.7024 - val_accuracy: 0.6833\n",
      "Epoch 127/128\n",
      "8/8 [==============================] - 5s 594ms/step - loss: 0.4307 - accuracy: 0.8250 - val_loss: 0.7024 - val_accuracy: 0.6000\n",
      "Epoch 128/128\n",
      "8/8 [==============================] - 5s 627ms/step - loss: 0.4615 - accuracy: 0.7833 - val_loss: 0.6983 - val_accuracy: 0.6833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26a7cdffef0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit_generator(x_train,steps_per_epoch=8,\n",
    "                    validation_data=x_test,epochs=128,\n",
    "                    validation_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained model with .h5 extension\n",
    "model.save('Missing_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Model Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import smtplib\n",
    "from keras.preprocessing import image \n",
    "import tensorflow as tf\n",
    "import os\n",
    "name = [\"Found Missing\",\"Normal\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Saved model \n",
    "model = tf.keras.models.load_model('Missing_1.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving Random Image Path\n",
    "img = image.load_img(r\"image_path\\t1.jpg\",target_size = (64,64))\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes of Prediction\n",
    "pred=model.predict_classes(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "SMb451e5a5711142f6b1df584f52922fe0\n",
      "Found Missing\n",
      "SMS Sent\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "0\n",
      "SMcc5f60aab6e640ae975cc7d7dbc08f04\n",
      "Found Missing\n",
      "SMS Sent\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "0\n",
      "SM5689d2babe1e49c0adb3157108f3027e\n",
      "Found Missing\n",
      "SMS Sent\n",
      "0\n",
      "SMec5fdc7f6328471389d6b18bcdde1737\n",
      "Found Missing\n",
      "SMS Sent\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "0\n",
      "SMc9a3e52ba8da4591b148afe07a16508e\n",
      "Found Missing\n",
      "SMS Sent\n",
      "1\n",
      "Normal\n",
      "0\n",
      "SM13c30e168d2746958322099ecd8eab5d\n",
      "Found Missing\n",
      "SMS Sent\n",
      "0\n",
      "SMec5e7fc42b304644a57b94e3a374b9af\n",
      "Found Missing\n",
      "SMS Sent\n",
      "0\n",
      "SM250d1ac072fd487fb0495abe2170062c\n",
      "Found Missing\n",
      "SMS Sent\n",
      "0\n",
      "SMa12002d96574450f8807b6622068cee8\n",
      "Found Missing\n",
      "SMS Sent\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "0\n",
      "SM8af9d47b35e24543a820d8abd4ca0659\n",
      "Found Missing\n",
      "SMS Sent\n",
      "0\n",
      "SMba0adb97944041288a1624daa83290bf\n",
      "Found Missing\n",
      "SMS Sent\n",
      "0\n",
      "SMa9933e33971a41feb49aeb2e0fcbebbc\n",
      "Found Missing\n",
      "SMS Sent\n",
      "0\n",
      "SMbc4c755384ff4ac9998dbec7d52e39ce\n",
      "Found Missing\n",
      "SMS Sent\n",
      "0\n",
      "SM6b34a780ac7a4e51aa849bdf92d98f70\n",
      "Found Missing\n",
      "SMS Sent\n",
      "0\n",
      "SMe38b4ea5d6354b2d8f16a1ef4b2c54d1\n",
      "Found Missing\n",
      "SMS Sent\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "0\n",
      "SM13607be814f64acf98137fe0fa78dd14\n",
      "Found Missing\n",
      "SMS Sent\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n",
      "1\n",
      "Normal\n"
     ]
    }
   ],
   "source": [
    "# Importing of Libraries\n",
    "#Import opencv Library\n",
    "import cv2\n",
    "# Import numpy library\n",
    "import numpy as np\n",
    "# Import Keras image processing Library\n",
    "from keras.preprocessing import image \n",
    "# Import Tensorflow library\n",
    "import tensorflow as tf\n",
    "# Import Client library from twilio\n",
    "from twilio.rest import Client\n",
    "\n",
    "# Loading the Saved Model\n",
    "model = tf.keras.models.load_model('Missing_1.h5') \n",
    "# Initialising the video \n",
    "video = cv2.VideoCapture(0)\n",
    "# Desired outputs\n",
    "name = [\"Found Missing\",\"Normal\"]\n",
    "\n",
    "while(True):\n",
    "    success, frame = video.read()\n",
    "    cv2.imwrite(\"image.jpg\",frame)\n",
    "    img = image.load_img(\"image.jpg\",target_size = (64,64))\n",
    "    x  = image.img_to_array(img)\n",
    "    x = np.expand_dims(x,axis = 0)\n",
    "    pred = model.predict_classes(x)\n",
    "    p = pred[0][0]\n",
    "    print(p)\n",
    "    cv2.putText(frame, \"Predicted  Class = \"+str(name[p]), (100,100), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "     \n",
    "    if pred[0][0]==0:\n",
    "        # Twilio Account Service ID\n",
    "        account_sid='ACec5c29dade0d5d23f9b93ea3f0c105e0'\n",
    "        # Twilio Account Auth Token\n",
    "        auth_token='72ed0ca874bc4114cd0f47ec02d4ff60'\n",
    "        # Initialise the client \n",
    "        client=Client(account_sid,auth_token)\n",
    "        # Creation of Message API\n",
    "        message=client.messages.create(\n",
    "        to=\"+91XXXXXXXXXX\", # Fillthe contact to your desired one\n",
    "        from_=\"XXXXXXXXX\", # Fill with your created Twilio number\n",
    "        body=\" Found the Missing at 17.3984° N, 78.5583° E\" # Alert SMS Text   \n",
    "        )\n",
    "        print(message.sid)\n",
    "        print(\"Found Missing\")\n",
    "        print('SMS Sent')\n",
    "    else:\n",
    "        print(\"Normal\")\n",
    "    \n",
    "    cv2.imshow(\"frame\",frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'): \n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}